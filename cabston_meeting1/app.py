import os
import re
import time
import psutil
import shutil
import warnings
import tempfile
import subprocess
import hashlib
import json
import requests
from pathlib import Path
from functools import lru_cache, wraps
from flask import Flask, jsonify, render_template, request, redirect, url_for, session
from flask_cors import CORS
from werkzeug.utils import secure_filename
from typing import List, Dict, Union
from langdetect import detect
from faster_whisper import WhisperModel
import onnxruntime as ort
from pydub import AudioSegment
import tiktoken

# ============== ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù…Ù† Ù…Ù„Ù .env (Ø¥Ù† ÙˆØ¬Ø¯) ==============
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # Ø¥Ø°Ø§ Ù„Ù… ØªØªÙˆÙØ± dotenv ØªØ¬Ø§Ù‡Ù„Ù‡Ø§ ÙÙ‚Ø·

# ============== Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙØ§ØªÙŠØ­ API ÙˆØ§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø© ==============
# ÙŠØ¬Ø¨ ØªØ¹ÙŠÙŠÙ† Ù‡Ø°Ù‡ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ÙÙŠ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ø£Ùˆ Ù…Ù„Ù .env
GROQ_API_KEY = os.environ.get('GROQ_API_KEY')  # Ù…ÙØªØ§Ø­ Groq API
username = os.environ.get('USERNAME')  # Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø«Ø§Ø¨Øª
password = os.environ.get('PASSWORD')  # ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø«Ø§Ø¨ØªØ©
SECRET_KEY = os.environ.get('SECRET_KEY')  # Ù…ÙØªØ§Ø­ Ø§Ù„Ø¬Ù„Ø³Ø© (ÙŠØ¬Ø¨ ØªØ¹ÙŠÙŠÙ†Ù‡ ÙÙŠ .env)

GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
GROQ_MODEL = "llama3-70b-8192"
GROQ_RATE_LIMIT_DELAY = 3  # ØªØ£Ø®ÙŠØ± Ø£ÙˆÙ„ÙŠ 3 Ø«ÙˆØ§Ù†Ù
GROQ_MAX_RETRIES = 5
GROQ_MAX_BACKOFF = 30  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„ØªØ£Ø®ÙŠØ± 30 Ø«Ø§Ù†ÙŠØ©

# ============== Ø§Ù„ØªÙ‡ÙŠØ¦Ø© ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ==============

app = Flask(__name__)
CORS(app)
app.secret_key = SECRET_KEY  # Ù…ÙØªØ§Ø­ Ø§Ù„Ø¬Ù„Ø³Ø©

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'
os.environ['TOKENIZERS_PARALLELISM'] = 'false'
SUPPORTED_LANGUAGES = {"Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©": "en", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "ar"}
MAX_FILE_SIZE = 5 * 1024 * 1024 * 1024  # 5 GB
MAX_RETRIES = 3
RETRY_DELAY = 1

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
MAX_CHUNK_SIZE_MB = 50  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø­Ø¬Ù… Ø§Ù„Ø¬Ø²Ø¡ Ø¨Ø§Ù„Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª
MIN_FREE_DISK_SPACE_MB = 1000  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ø­Ø±Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø§Ù„Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª
MIN_FREE_MEMORY_MB = 500  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø­Ø±Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø§Ù„Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª
TEMP_DIR = Path(tempfile.gettempdir()) / "audio_processing"
TEMP_DIR.mkdir(exist_ok=True, parents=True)

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
CACHE_DIR = Path("audio_cache")
CACHE_DIR.mkdir(exist_ok=True)

# ØªØ¬Ø§Ù‡Ù„ ØªØ­Ø°ÙŠØ±Ø§Øª ØºÙŠØ± Ø¶Ø±ÙˆØ±ÙŠØ©
warnings.filterwarnings("ignore", message="FP16 is not supported on CPU")
warnings.filterwarnings("ignore", category=UserWarning)

# ============== Ù†Ø¸Ø§Ù… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ==============

class ErrorLogger:
    @staticmethod
    def log_error(error_type, message, details=None):
        log_entry = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "error_type": error_type,
            "message": message,
            "details": details
        }
        print(f"âŒ [ERROR] {json.dumps(log_entry, ensure_ascii=False)}")
        
        # Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„ ÙÙŠ Ù…Ù„Ù
        log_file = Path("error_logs.json")
        try:
            if log_file.exists():
                with open(log_file, "r+", encoding="utf-8") as f:
                    logs = json.load(f)
                    logs.append(log_entry)
                    f.seek(0)
                    json.dump(logs, f, ensure_ascii=False, indent=2)
            else:
                with open(log_file, "w", encoding="utf-8") as f:
                    json.dump([log_entry], f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„: {str(e)}")

class ResourceManager:
    """ÙØ¦Ø© Ù„Ø¥Ø¯Ø§Ø±Ø© Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù†Ø¸Ø§Ù…"""
    
    @staticmethod
    def check_system_resources():
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªØ§Ø­Ø©"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ø­Ø±Ø©
            free_disk = shutil.disk_usage(TEMP_DIR).free / (1024 * 1024)  # Ø¨Ø§Ù„Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª
            if free_disk < MIN_FREE_DISK_SPACE_MB:
                raise ResourceWarning(f"Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù‚Ø±Øµ ØºÙŠØ± ÙƒØ§ÙÙŠØ©. Ø§Ù„Ù…ØªØ§Ø­: {free_disk:.0f}MB")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©
            free_memory = psutil.virtual_memory().available / (1024 * 1024)  # Ø¨Ø§Ù„Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª
            if free_memory < MIN_FREE_MEMORY_MB:
                raise ResourceWarning(f"Ø§Ù„Ø°Ø§ÙƒØ±Ø© ØºÙŠØ± ÙƒØ§ÙÙŠØ©. Ø§Ù„Ù…ØªØ§Ø­: {free_memory:.0f}MB")
            
            return True
        except Exception as e:
            ErrorLogger.log_error("ResourceCheck", str(e))
            return False
    
    @staticmethod
    def cleanup_temp_files(older_than_hours=24):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        try:
            current_time = time.time()
            for temp_file in TEMP_DIR.glob("*"):
                if temp_file.is_file():
                    file_age = current_time - temp_file.stat().st_mtime
                    if file_age > older_than_hours * 3600:
                        temp_file.unlink(missing_ok=True)
        except Exception as e:
            ErrorLogger.log_error("Cleanup", "ÙØ´Ù„ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©", str(e))

class RetryManager:
    """ÙØ¦Ø© Ù„Ø¥Ø¯Ø§Ø±Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª"""
    
    @staticmethod
    def with_retry(func, *args, max_retries=MAX_RETRIES, delay=RETRY_DELAY, **kwargs):
        """ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ø§Ù„Ø© Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„"""
        last_error = None
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    time.sleep(delay * attempt)  # ØªØ£Ø®ÙŠØ± ØªØµØ§Ø¹Ø¯ÙŠ
                return func(*args, **kwargs)
            except Exception as e:
                last_error = e
                ErrorLogger.log_error(
                    "RetryAttempt",
                    f"ÙØ´Ù„Øª Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}/{max_retries}",
                    str(e)
                )
        raise last_error

# ============== ÙØ¦Ø§Øª Ø§Ù„Ù…ØµÙ†Ø¹ Ù…Ø¹ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª ==============

class ModelLoader:
    """ÙØ¦Ø© Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¹ Ø¯Ø¹Ù… GPU/CPU Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ"""
    
    _instance = None
    _models_loaded = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._models = {}
            cls._instance._device = cls._instance._select_device()
            cls._instance._onnx_sessions = {}
            
            print(f"âš¡ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {cls._instance._device}")
            
            if cls._instance._device.type == 'cpu':
                ort.set_default_logger_severity(3)
        return cls._instance
    
    def _select_device(self):
        """Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ø£Ù…Ø«Ù„"""
        try:
            providers = ort.get_available_providers()
            if "CUDAExecutionProvider" in providers:
                print("CUDA Ù…ØªØ§Ø­ØŒ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡")
                return type("Device", (), {"type": "cuda"})()
        except Exception:
            pass
        return type("Device", (), {"type": "cpu"})()
    
    def preload_models(self):
        """ØªØ­Ù…ÙŠÙ„ Ù…Ø³Ø¨Ù‚ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        if not self._models_loaded:
            print("âš¡ Ø¬Ø§Ø±Ù ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø³Ø¨Ù‚Ø§Ù‹...")
            start_time = time.time()
            
            try:
                self._load_onnx_models()
            except Exception as e:
                ErrorLogger.log_error("ModelLoad", "ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ ONNX", str(e))
            
            self._models_loaded = True
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙÙŠ {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©")
    
    def _load_onnx_models(self):
        """ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ ONNX Ø§Ù„Ù…Ø­Ø³Ù†Ø©"""
        pass
    
    def get_whisper_model(self):
        if 'whisper' not in self._models:
            print("âš¡ Ø¬Ø§Ø±Ù ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Faster Whisper...")
            start_time = time.time()
            try:
                compute_type = "float16" if self._device.type == 'cuda' else "float32"
                device = "cuda" if self._device.type == 'cuda' else "cpu"
                
                model = WhisperModel(
                    "small",
                    device=device,
                    compute_type=compute_type,
                    cpu_threads=min(4, os.cpu_count() or 1) if device == "cpu" else 0,
                    num_workers=1
                )
                
                self._models['whisper'] = model
                print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Faster Whisper ÙÙŠ {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©")
            except Exception as e:
                ErrorLogger.log_error("ModelLoad", "ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Faster Whisper", str(e))
                return None
        return self._models['whisper']
    

model_loader = ModelLoader()

# ============== Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ø§Ù„Ù…Ø­Ø³Ù† ==============

class AudioCache:
    """ÙØ¦Ø© Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù…Ø¹ ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…Ù„ÙØ§Øª"""
    
    @staticmethod
    def get_file_hash(file_path):
        """Ø­Ø³Ø§Ø¨ hash Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù…Ù„Ù"""
        hash_sha256 = hashlib.sha256()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_sha256.update(chunk)
        return hash_sha256.hexdigest()
    
    @staticmethod
    def get_cache_path(file_hash):
        """ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ© ÙÙŠ Ù…Ø¬Ù„Ø¯Ø§Øª ÙØ±Ø¹ÙŠØ©"""
        subdir = CACHE_DIR / file_hash[:2]
        subdir.mkdir(exist_ok=True)
        return subdir / f"{file_hash}.json"
    
    @staticmethod
    def check_cache(file_path):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ù…Ù„Ù"""
        file_hash = AudioCache.get_file_hash(file_path)
        cache_file = AudioCache.get_cache_path(file_hash)
        
        if cache_file.exists():
            try:
                with open(cache_file, "r", encoding="utf-8") as f:
                    cache_data = json.load(f)
                    
                    if (os.path.getsize(file_path) == cache_data["file_size"] and 
                        os.path.getmtime(file_path) == cache_data["last_modified"]):
                        return cache_data["transcription"]
            except Exception as e:
                ErrorLogger.log_error("CacheError", "ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª", str(e))
        return None
    
    @staticmethod
    def save_to_cache(file_path, transcription):
        """Ø­ÙØ¸ Ø§Ù„ØªÙØ±ÙŠØº Ø§Ù„ØµÙˆØªÙŠ ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        file_hash = AudioCache.get_file_hash(file_path)
        cache_file = AudioCache.get_cache_path(file_hash)
        
        cache_data = {
            "file_hash": file_hash,
            "file_size": os.path.getsize(file_path),
            "last_modified": os.path.getmtime(file_path),
            "transcription": transcription,
            "timestamp": time.time()
        }
        
        try:
            with open(cache_file, "w", encoding="utf-8") as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            ErrorLogger.log_error("CacheError", "ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª", str(e))
        
        return cache_data

# ============== Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© ==============

class TextProcessor:
    """ÙØ¦Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ù„Ù„Ø£Ø¯Ø§Ø¡"""
    
    @staticmethod
    @lru_cache(maxsize=500)
    def clean_text(text):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"""
        if not text:
            return ""
        
        text = re.sub(r'[.ØŸ!ØŒØ›]+', '.', text)
        text = re.sub(r'(\S+)( \1)+', r'\1', text)
        text = re.sub(r'http\S+|www\S+|@\S+', '', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        sentences = [s.strip() for s in text.split('.') if s.strip()]
        if not sentences:
            return ""
        
        if TextProcessor.detect_language_safe(text) == "ar":
            sentences = [s[0].upper() + s[1:] if s else s for s in sentences]
        else:
            sentences = [s.capitalize() for s in sentences]
        
        return '. '.join(sentences) + '.' if sentences else ''

    @staticmethod
    @lru_cache(maxsize=100)
    def detect_language_safe(text):
        """ÙƒØ´Ù Ø§Ù„Ù„ØºØ© Ù…Ø¹ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡"""
        if not text:
            return "en"
        try:
            lang = detect(text[:500])
            return "ar" if lang == "ar" else "en"
        except Exception as e:
            ErrorLogger.log_error("LanguageDetection", "ÙØ´Ù„ ÙƒØ´Ù Ø§Ù„Ù„ØºØ©", str(e))
            return "en"

    @staticmethod
    def fast_text_split(text, max_chars=5000):
        """ØªÙ‚Ø³ÙŠÙ… Ø³Ø±ÙŠØ¹ Ù„Ù„Ù†Øµ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª"""
        if len(text) <= max_chars:
            return [text]
        split_pos = text.rfind(' ', 0, max_chars)
        return [text[:split_pos]] + TextProcessor.fast_text_split(text[split_pos+1:], max_chars)

class FileProcessor:
    """ÙØ¦Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© ÙÙ‚Ø·"""
    @staticmethod
    def process_uploaded_file(file):
        if not file:
            print("===> process_uploaded_file: No file object received")
            return None, "Ù„Ù… ÙŠØªÙ… ØªÙ‚Ø¯ÙŠÙ… Ù…Ù„Ù"
        file.seek(0, os.SEEK_END)
        file_size = file.tell()
        file.seek(0)
        filename = secure_filename(file.filename)
        file_ext = filename.lower().split('.')[-1]
        print(f"===> process_uploaded_file: filename={filename}, size={file_size}, ext={file_ext}")
        if file_size > MAX_FILE_SIZE:
            print(f"===> process_uploaded_file: File too large: {file_size}")
            return None, "Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù ÙŠØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ (5GB)"
        # Ø§Ù„Ø³Ù…Ø§Ø­ ÙÙ‚Ø· Ø¨Ø§Ù…ØªØ¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙˆØª
        if file_ext not in ['wav', 'mp3', 'ogg', 'flac', 'm4a', 'webm']:
            return None, "Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…ØŒ ÙÙ‚Ø· Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ù…Ø³Ù…ÙˆØ­Ø©"
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{file_ext}") as temp_file:
                file.save(temp_file.name)
                print(f"===> process_uploaded_file: Saved to temp: {temp_file.name}")
                return temp_file.name, None
        except Exception as e:
            ErrorLogger.log_error("FileUpload", "ÙØ´Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙˆØ¹", str(e))
            print(f"===> process_uploaded_file: Exception: {str(e)}")
            return None, f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {str(e)}"

    @staticmethod
    def process_audio_file(file_path):
        try:
            print(f"===> process_audio_file: file_path={file_path}")
            cached_text = AudioCache.check_cache(file_path)
            if cached_text:
                print(f"âš¡ ØªÙ… Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„ØªÙØ±ÙŠØº Ù…Ù† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª")
                return cached_text
            # Ø§Ø³ØªØ®Ø¯Ù… Faster Whisper Ø§Ù„Ù…Ø­Ù„ÙŠ
            text = AudioProcessor.recognize_speech(file_path)
            if not text:
                raise ValueError("Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ")
            AudioCache.save_to_cache(file_path, text)
            return text
        except Exception as e:
            ErrorLogger.log_error("AudioProcessing", "ÙØ´Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ", str(e))
            print(f"===> process_audio_file: Exception: {str(e)}")
            return f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ: {str(e)}"
        finally:
            if file_path.endswith('_optimized.wav'):
                try:
                    os.remove(file_path)
                except:
                    pass
    
class AudioProcessor:
    """ÙØ¦Ø© Ù…ØªØ®ØµØµØ© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©"""
    
    @staticmethod
    def validate_audio_file(audio_path):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù
            if not os.path.exists(audio_path):
                raise ValueError("Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù
            file_size = os.path.getsize(audio_path)
            if file_size == 0:
                raise ValueError("Ø§Ù„Ù…Ù„Ù ÙØ§Ø±Øº")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
            audio = AudioSegment.from_file(audio_path)
            if len(audio) == 0:
                raise ValueError("Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ ÙØ§Ø±Øº")
            if audio.duration_seconds < 0.1:
                raise ValueError("Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹")
            
            return True
        except Exception as e:
            ErrorLogger.log_error("AudioValidation", "ÙØ´Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ", str(e))
            return False
    
    @staticmethod
    def optimize_audio_for_whisper(input_path, output_path):
        """ØªØ­Ø³ÙŠÙ† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙˆØª Ù„Ø²ÙŠØ§Ø¯Ø© Ø³Ø±Ø¹Ø© Whisper"""
        try:
            if not ResourceManager.check_system_resources():
                raise ResourceWarning("Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª")
            
            if not AudioProcessor.validate_audio_file(input_path):
                raise ValueError("Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ ØºÙŠØ± ØµØ§Ù„Ø­")
            
            command = [
                'ffmpeg',
                '-i', input_path,
                '-ar', '16000',
                '-ac', '1',
                '-c:a', 'pcm_s16le',
                '-y',
                '-hide_banner',
                '-loglevel', 'error',
                output_path
            ]
            
            result = RetryManager.with_retry(
                subprocess.run,
                command,
                check=True,
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                raise RuntimeError(f"ÙØ´Ù„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª: {result.stderr}")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ø§ØªØ¬
            if not AudioProcessor.validate_audio_file(output_path):
                raise ValueError("ÙØ´Ù„ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ")
            
            return True
        except Exception as e:
            ErrorLogger.log_error("AudioOptimization", "ÙØ´Ù„ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØª", str(e))
            return False
    
    @staticmethod
    def recognize_speech(audio_path):
        """Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… ÙÙŠ Ù…Ù„Ù ØµÙˆØªÙŠ"""
        if not AudioProcessor.validate_audio_file(audio_path):
            return "Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ ØºÙŠØ± ØµØ§Ù„Ø­"
        
        model = model_loader.get_whisper_model()
        if not model:
            return "Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… ØºÙŠØ± Ù…ØªØ§Ø­"
        
        try:
            segments, info = model.transcribe(
                audio_path,
                beam_size=5,
                word_timestamps=True,
                vad_filter=True,
                vad_parameters=dict(min_silence_duration_ms=500)
            )
            
            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Øµ Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹
            transcription = " ".join([segment.text for segment in segments]).strip()
            
            if not transcription:
                raise ValueError("Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø£ÙŠ Ù†Øµ")
            
            AudioCache.save_to_cache(audio_path, transcription)
            return transcription
        except Exception as e:
            ErrorLogger.log_error("SpeechRecognition", "ÙØ´Ù„ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…", str(e))
            return f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {str(e)}"
    
    @staticmethod
    def process_large_audio(audio_path, chunk_size=MAX_CHUNK_SIZE_MB):
        """ØªØ¬Ø²Ø¦Ø© ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ø§Ù„ÙƒØ¨ÙŠØ±Ø©"""
        if not ResourceManager.check_system_resources():
            raise ResourceWarning("Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„ÙƒØ¨ÙŠØ±")
        
        if not AudioProcessor.validate_audio_file(audio_path):
            raise ValueError("Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ ØºÙŠØ± ØµØ§Ù„Ø­")
        
        model = model_loader.get_whisper_model()
        if not model:
            raise RuntimeError("Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… ØºÙŠØ± Ù…ØªØ§Ø­")
        
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø­Ø¬Ù… Ù…Ù† Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª Ø¥Ù„Ù‰ Ù…ÙŠÙ„Ù„ÙŠ Ø«Ø§Ù†ÙŠØ©
            chunk_duration = chunk_size * 1000  # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù…ÙŠÙ„Ù„ÙŠ Ø«Ø§Ù†ÙŠØ©
            
            audio = AudioSegment.from_file(audio_path)
            duration = len(audio)
            
            if duration == 0:
                raise ValueError("Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ ÙØ§Ø±Øº")
            
            chunks = []
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ù…Ø¤Ù‚Øª Ù„Ù„Ø£Ø¬Ø²Ø§Ø¡
            temp_chunk_dir = TEMP_DIR / f"chunks_{int(time.time())}"
            temp_chunk_dir.mkdir(exist_ok=True)
            
            try:
                for i in range(0, int(duration), chunk_duration):
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ù‚Ø¨Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø¬Ø²Ø¡
                    if not ResourceManager.check_system_resources():
                        raise ResourceWarning("Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ù…ÙˆØ§ØµÙ„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©")
                    
                    start = i
                    end = min(i + chunk_duration, duration)
                    chunk = audio[start:end]
                    
                    if len(chunk) == 0:
                        continue
                    
                    # Ø­ÙØ¸ Ø§Ù„Ø¬Ø²Ø¡ ÙÙŠ Ù…Ù„Ù Ù…Ø¤Ù‚Øª
                    chunk_path = temp_chunk_dir / f"chunk_{i}.wav"
                    chunk.export(chunk_path, format="wav", codec="pcm_s16le")
                    
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¬Ø²Ø¡
                    if not AudioProcessor.validate_audio_file(str(chunk_path)):
                        ErrorLogger.log_error("ChunkValidation", f"Ø¬Ø²Ø¡ ØºÙŠØ± ØµØ§Ù„Ø­: chunk_{i}.wav")
                        continue
                    
                    # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¬Ø²Ø¡
                    optimized_path = temp_chunk_dir / f"chunk_{i}_opt.wav"
                    if AudioProcessor.optimize_audio_for_whisper(str(chunk_path), str(optimized_path)):
                        try:
                            # Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… ÙÙŠ Ø§Ù„Ø¬Ø²Ø¡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Faster Whisper
                            segments, info = RetryManager.with_retry(
                                model.transcribe,
                                str(optimized_path),
                                beam_size=5,
                                word_timestamps=True,
                                vad_filter=True,
                                vad_parameters=dict(min_silence_duration_ms=500)
                            )
                            chunk_text = " ".join([segment.text for segment in segments]).strip()
                            if chunk_text:
                                chunks.append(chunk_text)
                        except Exception as e:
                            ErrorLogger.log_error("ChunkProcessing", f"ÙØ´Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¬Ø²Ø¡ {i}", str(e))
                    
                    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ù„Ù„Ø¬Ø²Ø¡
                    chunk_path.unlink(missing_ok=True)
                    optimized_path.unlink(missing_ok=True)
            
            finally:
                # ØªÙ†Ø¸ÙŠÙ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡
                shutil.rmtree(temp_chunk_dir, ignore_errors=True)
            
            if not chunks:
                raise ValueError("Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø£ÙŠ Ù†Øµ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡")
            
            transcription = " ".join(chunks)
            
            # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
            AudioCache.save_to_cache(audio_path, transcription)
            return transcription
            
        except Exception as e:
            ErrorLogger.log_error("LargeAudioProcessing", "ÙØ´Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„ÙƒØ¨ÙŠØ±", str(e))
            raise RuntimeError(f"ÙØ´Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„ÙƒØ¨ÙŠØ±: {str(e)}")


class GroqAPI:
    """ÙØ¦Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Groq API"""
    
    _last_request_time = 0  # ØªØªØ¨Ø¹ ÙˆÙ‚Øª Ø¢Ø®Ø± Ø·Ù„Ø¨
    
    @staticmethod
    def _wait_for_rate_limit():
        """Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù„Ù„Ø§Ù…ØªØ«Ø§Ù„ Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù…Ø¹Ø¯Ù„"""
        current_time = time.time()
        time_since_last_request = current_time - GroqAPI._last_request_time
        if time_since_last_request < GROQ_RATE_LIMIT_DELAY:
            wait_time = GROQ_RATE_LIMIT_DELAY - time_since_last_request
            print(f"â³ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± {wait_time:.1f} Ø«ÙˆØ§Ù†Ù Ù„Ù„Ø§Ù…ØªØ«Ø§Ù„ Ù„Ø­Ø¯ Ø§Ù„Ù…Ø¹Ø¯Ù„...")
            time.sleep(wait_time)
        GroqAPI._last_request_time = time.time()
    
    @staticmethod
    def _handle_rate_limit(retry_count):
        """Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø£Ø®Ø·Ø§Ø¡ Ø­Ø¯ Ø§Ù„Ù…Ø¹Ø¯Ù„"""
        if retry_count >= GROQ_MAX_RETRIES:
            raise RuntimeError("ØªÙ… ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©")
        # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ£Ø®ÙŠØ± Ø¨Ø´ÙƒÙ„ ØªØµØ§Ø¹Ø¯ÙŠ Ù…Ø¹ Ø­Ø¯ Ø£Ù‚ØµÙ‰
        wait_time = min(GROQ_RATE_LIMIT_DELAY * (2 ** retry_count), GROQ_MAX_BACKOFF)
        print(f"â³ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± {wait_time} Ø«ÙˆØ§Ù†Ù Ù‚Ø¨Ù„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©...")
        time.sleep(wait_time)
    
    @staticmethod
    def _make_api_request(data, retry_count=0):
        """Ø¥Ø¬Ø±Ø§Ø¡ Ø·Ù„Ø¨ API Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©"""
        GroqAPI._wait_for_rate_limit()
        
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }
        
        try:
            response = requests.post(GROQ_API_URL, headers=headers, json=data, timeout=30)
            print(f"ğŸ“¡ Ø­Ø§Ù„Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {response.status_code}")
            
            if response.status_code == 429:
                if retry_count < GROQ_MAX_RETRIES:
                    print(f"âš  ØªÙ… ØªØ¬Ø§ÙˆØ² Ø­Ø¯ Ø§Ù„Ù…Ø¹Ø¯Ù„ (Ù…Ø­Ø§ÙˆÙ„Ø© {retry_count + 1}/{GROQ_MAX_RETRIES})")
                    GroqAPI._handle_rate_limit(retry_count)
                    return GroqAPI._make_api_request(data, retry_count + 1)
                else:
                    raise RuntimeError("ØªÙ… ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©")
            
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            if retry_count < GROQ_MAX_RETRIES:
                print(f"âš  Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø·Ù„Ø¨ (Ù…Ø­Ø§ÙˆÙ„Ø© {retry_count + 1}/{GROQ_MAX_RETRIES}): {str(e)}")
                GroqAPI._handle_rate_limit(retry_count)
                return GroqAPI._make_api_request(data, retry_count + 1)
            raise
    
    @staticmethod
    def test_connection():
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Groq API"""
        try:
            data = {
                "model": GROQ_MODEL,
                "messages": [
                    {"role": "user", "content": "Hello, this is a test message."}
                ]
            }
            
            print("ğŸ”„ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Groq API...")
            print(f"ğŸ”— URL: {GROQ_API_URL}")
            print(f"ğŸ¤– Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {GROQ_MODEL}")
            print(f"ğŸ“¤ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±Ø³Ù„Ø©: {data}")
            
            result = GroqAPI._make_api_request(data)
            print("âœ… ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù†Ø¬Ø§Ø­!")
            return True
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„: {str(e)}")
            if hasattr(e, 'response') and e.response is not None:
                print(f"ğŸ“„ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£: {e.response.text}")
            return False
    
    @staticmethod
    def get_summary(text, lang="en"):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ù„Ø®Øµ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Groq API"""
        if not GROQ_API_KEY:
            raise ValueError("GROQ_API_KEY ØºÙŠØ± Ù…ØªÙˆÙØ± ÙÙŠ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©")
        
        # ØªØ­Ø¯ÙŠØ¯ System Prompt Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù„ØºØ©
        meeting_prompt = (
            "You are an expert meeting summarizer.\n\n"
            "I will give you a transcript of a meeting. Please do the following:\n\n"
            "1. Summarize the key discussion points in a clear and concise way.\n"
            "2. Extract and list all decisions that were made during the meeting.\n"
            "3. If applicable, include any action items or tasks and who they were assigned to.\n\n"
            "Output format:\n"
            "- Summary:\n[Your summary here]\n\n"
            "- Decisions Made:\n[Bullet list of decisions]\n\n"
            "- Action Items:\n[Bullet list of action items, if mentioned]\n\n"
            "Meeting Transcript:\n\"\"\"\n[Ø¶Ø¹ Ù‡Ù†Ø§ Ù†Øµ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹]\n\"\"\"\n"
        )
        system_prompt = meeting_prompt
        
        print(f"ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Groq API...")
        print(f"ğŸ“ Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©: {lang}")
        
        try:
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø·ÙˆÙŠÙ„Ø§Ù‹
            MAX_CHUNK_SIZE = 4000
            text_chunks = TextProcessor.fast_text_split(text, MAX_CHUNK_SIZE)
            summaries = []
            
            for i, chunk in enumerate(text_chunks, 1):
                print(f"ğŸ”„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¬Ø²Ø¡ {i} Ù…Ù† {len(text_chunks)}...")
                
                data = {
                    "model": GROQ_MODEL,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": chunk}
                    ]
                }
                
                print(f"ğŸ“¤ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ù„Ù„Ø¬Ø²Ø¡ {i}...")
                result = GroqAPI._make_api_request(data)
                
                if "choices" in result and len(result["choices"]) > 0:
                    chunk_summary = result["choices"][0]["message"]["content"].strip()
                    summaries.append(chunk_summary)
                    print(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù„Ø®Øµ Ø§Ù„Ø¬Ø²Ø¡ {i} Ø¨Ù†Ø¬Ø§Ø­")
                else:
                    print(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ø®Øµ ÙÙŠ Ø§Ù„Ø±Ø¯ Ù„Ù„Ø¬Ø²Ø¡ {i}")
                    print(f"ğŸ“„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¯: {result}")
                    raise ValueError(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ø®Øµ ÙÙŠ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Groq API Ù„Ù„Ø¬Ø²Ø¡ {i}")
            
            # Ø¯Ù…Ø¬ Ø§Ù„Ù…Ù„Ø®ØµØ§Øª
            if len(summaries) > 1:
                combined_summary = " ".join(summaries)
                if len(combined_summary) > MAX_CHUNK_SIZE:
                    return GroqAPI.get_summary(combined_summary, lang)  # ØªÙ„Ø®ÙŠØµ ØªÙƒØ±Ø§Ø±ÙŠ
                return combined_summary
            elif len(summaries) == 1:
                return summaries[0]
            else:
                raise ValueError("Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø£ÙŠ Ù…Ù„Ø®ØµØ§Øª")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(e)}")
            ErrorLogger.log_error("GroqAPI", "Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨ Groq API", str(e))
            raise RuntimeError(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨ Groq API: {str(e)}")

class GroqTranslator:
    """ÙØ¦Ø© Ù„Ù„ØªØ±Ø¬Ù…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Groq API"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"""
        self.api_key = GROQ_API_KEY
        if not self.api_key:
            raise ValueError("ÙŠØ¬Ø¨ ØªØ¹ÙŠÙŠÙ† GROQ_API_KEY ÙÙŠ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©")
        
        self.api_url = GROQ_API_URL
        self.model = GROQ_MODEL
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ£Ø®ÙŠØ± ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
        self.initial_delay = 3  # ØªØ£Ø®ÙŠØ± Ø£ÙˆÙ„ÙŠ 3 Ø«ÙˆØ§Ù†Ù
        self.max_retries = 5
        self.max_backoff = 30  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„ØªØ£Ø®ÙŠØ± 30 Ø«Ø§Ù†ÙŠØ©
    
    def _get_system_prompt(self, source_lang, target_lang):
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ØªØ±Ø¬Ù…Ø©"""
        if source_lang == 'ar' and target_lang == 'en':
            return """You are a professional Arabic to English translator. Translate the following Arabic text into fluent, academic English. Maintain the original meaning and context. Translate historical terms and names accurately. Do not add any explanations or notes. Keep the translation formal and precise. Only return the translation, nothing else."""
        elif source_lang == 'en' and target_lang == 'ar':
            return """Ø£Ù†Øª Ù…ØªØ±Ø¬Ù… Ù…Ø­ØªØ±Ù Ù…Ù† Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. Ù‚Ù… Ø¨ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ Ø³Ù„Ø³. Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù†Ù‰ ÙˆØ§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø£ØµÙ„ÙŠ. ØªØ±Ø¬Ù… Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª ÙˆØ§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ø¨Ø¯Ù‚Ø©. Ù„Ø§ ØªØ¶Ù Ø£ÙŠ Ø´Ø±ÙˆØ­Ø§Øª Ø£Ùˆ Ù…Ù„Ø§Ø­Ø¸Ø§Øª. Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø±Ø³Ù…ÙŠ ÙˆØ§Ù„Ø¯Ù‚ÙŠÙ‚. Ù‚Ù… Ø¨Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„ØªØ±Ø¬Ù…Ø© ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø¥Ø¶Ø§ÙØ§Øª."""
        else:
            raise ValueError(f"Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ØªØ±Ø¬Ù…Ø© ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…: Ù…Ù† {source_lang} Ø¥Ù„Ù‰ {target_lang}")
    
    def _make_api_request(self, text, system_prompt, retry_count=0):
        """Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨ Ø¥Ù„Ù‰ Groq API Ù…Ø¹ Ø¯Ø¹Ù… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text}
            ],
            "temperature": 0.3,  # Ù‚ÙŠÙ…Ø© Ù…Ù†Ø®ÙØ¶Ø© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø£ÙƒØ«Ø± Ø¯Ù‚Ø©
            "max_tokens": 4000
        }
        
        try:
            delay = min(self.initial_delay * (2 ** retry_count), self.max_backoff)
            time.sleep(delay)
            
            print(f"ğŸ”„ Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨ Ø§Ù„ØªØ±Ø¬Ù…Ø© (Ù…Ø­Ø§ÙˆÙ„Ø© {retry_count + 1})")
            response = requests.post(self.api_url, headers=headers, json=data, timeout=30)
            
            if response.status_code == 429:  # ØªØ¬Ø§ÙˆØ² Ø­Ø¯ Ø§Ù„Ù…Ø¹Ø¯Ù„
                if retry_count < self.max_retries:
                    print(f"âš  ØªÙ… ØªØ¬Ø§ÙˆØ² Ø­Ø¯ Ø§Ù„Ù…Ø¹Ø¯Ù„. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {retry_count + 1}/{self.max_retries}")
                    return self._make_api_request(text, system_prompt, retry_count + 1)
                raise Exception("ØªÙ… ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©")
            
            response.raise_for_status()
            result = response.json()
            
            if "choices" in result and len(result["choices"]) > 0:
                translation = result["choices"][0]["message"]["content"].strip()
                print("âœ… ØªÙ…Øª Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¨Ù†Ø¬Ø§Ø­")
                return translation
            
            raise Exception("Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØºÙŠØ± ØµØ§Ù„Ø­Ø© Ù…Ù† API")
            
        except requests.exceptions.RequestException as e:
            if retry_count < self.max_retries:
                print(f"âš  Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø·Ù„Ø¨. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {retry_count + 1}/{self.max_retries}")
                return self._make_api_request(text, system_prompt, retry_count + 1)
            raise Exception(f"ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Groq API: {str(e)}")
        except Exception as e:
            if retry_count < self.max_retries:
                print(f"âš  Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {retry_count + 1}/{self.max_retries}")
                time.sleep(self.initial_delay)
                return self._make_api_request(text, system_prompt, retry_count + 1)
            raise

    def split_text(self, text: str) -> List[str]:
        """ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ù…Ù† Ø§Ù„ØªÙˆÙƒÙ†Ø²"""
        chunks = []
        current_chunk = []
        current_length = 0
        
        sentences = text.split('.')
        
        for sentence in sentences:
            sentence = sentence.strip() + '.'
            sentence_tokens = self.count_tokens(sentence)
            
            if sentence_tokens > self.chunk_size:
                sub_sentences = sentence.split('ØŒ' if self.detect_language(sentence) == 'ar' else ',')
                for sub_sentence in sub_sentences:
                    sub_sentence = sub_sentence.strip() + ','
                    sub_tokens = self.count_tokens(sub_sentence)
                    
                    if current_length + sub_tokens > self.chunk_size:
                        chunks.append('.'.join(current_chunk))
                        current_chunk = [sub_sentence]
                        current_length = sub_tokens
                    else:
                        current_chunk.append(sub_sentence)
                        current_length += sub_tokens
            else:
                if current_length + sentence_tokens > self.chunk_size:
                    chunks.append('.'.join(current_chunk))
                    current_chunk = [sentence]
                    current_length = sentence_tokens
                else:
                    current_chunk.append(sentence)
                    current_length += sentence_tokens
        
        if current_chunk:
            chunks.append('.'.join(current_chunk))
        
        return chunks
    
    def translate(self, text, target_lang=None, source_lang=None, max_chunk_size=4000):
        try:
            if not text or not text.strip():
                return text

            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ù…ØµØ¯Ø± ÙˆØ§Ù„Ù‡Ø¯Ù
            source_lang = source_lang or detect(text[:1000])
            target_lang = target_lang or "en"

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            cached = TranslationCache.get_cached_translation(text, source_lang, target_lang)
            if cached:
                print("âœ… ØªÙ… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©")
                return cached

            # ØªØ­Ø¶ÙŠØ± Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
            system_prompt = self._get_system_prompt(source_lang, target_lang)

            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø·ÙˆÙŠÙ„Ø§Ù‹
            if len(text) > max_chunk_size:
                print("âš¡ Ø§Ù„Ù†Øµ Ø·ÙˆÙŠÙ„ØŒ Ø³ÙŠØªÙ… ØªÙ‚Ø³ÙŠÙ…Ù‡...")
                chunks = self.split_text(text)
                translated_chunks = []

                for i, chunk in enumerate(chunks, 1):
                    print(f"\nğŸ”„ ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¬Ø²Ø¡ {i}/{len(chunks)}...")
                    translated_chunk = self._make_api_request(chunk, system_prompt)
                    if translated_chunk:
                        translated_chunks.append(translated_chunk)
                        print(f"âœ“ ØªÙ…Øª ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¬Ø²Ø¡ {i}")
                    else:
                        raise Exception(f"ÙØ´Ù„ ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¬Ø²Ø¡ {i}")

                    # ØªØ£Ø®ÙŠØ± Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡
                    if i < len(chunks):
                        delay = min(2 * i, 5)  # ØªØ£Ø®ÙŠØ± ØªØ¯Ø±ÙŠØ¬ÙŠ Ù…Ø¹ Ø­Ø¯ Ø£Ù‚ØµÙ‰ 5 Ø«ÙˆØ§Ù†Ù
                        print(f"â³ Ø§Ù†ØªØ¸Ø§Ø± {delay} Ø«ÙˆØ§Ù†Ù Ù‚Ø¨Ù„ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„ØªØ§Ù„ÙŠ...")
                        time.sleep(delay)

                if translated_chunks:
                    final_translation = " ".join(translated_chunks)
                    # ØªØ®Ø²ÙŠÙ† ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
                    TranslationCache.cache_translation(text, source_lang, target_lang, final_translation)
                    print("âœ… ØªÙ…Øª Ø§Ù„ØªØ±Ø¬Ù…Ø© ÙˆØ­ÙØ¸Ù‡Ø§ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©")
                    return final_translation
                else:
                    raise Exception("Ù„Ù… ÙŠØªÙ… ØªØ±Ø¬Ù…Ø© Ø£ÙŠ Ø¬Ø²Ø¡ Ø¨Ù†Ø¬Ø§Ø­")
            else:
                print("â„¹ Ø§Ù„Ù†Øµ Ù‚ØµÙŠØ± Ø¨Ù…Ø§ ÙŠÙƒÙÙŠ Ù„Ù„ØªØ±Ø¬Ù…Ø© Ù…Ø¨Ø§Ø´Ø±Ø©")
                translation = self._make_api_request(text, system_prompt)
                if translation:
                    # ØªØ®Ø²ÙŠÙ† ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
                    TranslationCache.cache_translation(text, source_lang, target_lang, translation)
                    print("âœ… ØªÙ…Øª Ø§Ù„ØªØ±Ø¬Ù…Ø© ÙˆØ­ÙØ¸Ù‡Ø§ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©")
                    return translation
                else:
                    raise Exception("ÙØ´Ù„Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ±Ø¬Ù…Ø©")

        except Exception as e:
            error_msg = str(e)
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ±Ø¬Ù…Ø©: {error_msg}")
            ErrorLogger.log_error("Translation", "ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ±Ø¬Ù…Ø©", error_msg)
            return text

class SummaryTranslator:
    """ÙØ¦Ø© Ù„Ù„ØªÙ„Ø®ÙŠØµ ÙˆØ§Ù„ØªØ±Ø¬Ù…Ø©"""
    
    _translator = None
    
    @staticmethod
    def get_translator():
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Ø³Ø®Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ø§Ù„Ù…ØªØ±Ø¬Ù…"""
        if SummaryTranslator._translator is None:
            SummaryTranslator._translator = GroqTranslator()
        return SummaryTranslator._translator
    
    @staticmethod
    def process_text_for_summary(text, source_lang=None, target_lang="en"):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ù„Ù„ØªÙ„Ø®ÙŠØµ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ø¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¯ÙˆÙ…Ù‹Ø§"""
        try:
            if not source_lang:
                source_lang = TextProcessor.detect_language_safe(text)
                source_lang = LanguageManager.normalize_language_code(source_lang)
            summarizer = GroqSummarizer()
            result = summarizer.summarize(text)
            if result["status"] == "success":
                summary = result["final_summary"]
                # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ø®ØªÙ„ÙØ© Ø¹Ù† Ù„ØºØ© Ø§Ù„Ù…ØµØ¯Ø±
                if target_lang != source_lang:
                    translator = SummaryTranslator.get_translator()
                    translated_summary = translator.translate(
                        summary,
                        target_lang=target_lang,
                        source_lang=source_lang
                    )
                    if translated_summary:
                        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ±Ø¬Ù…Ø©
                        cleaned = summarizer.clean_summary(translated_summary)
                        return [cleaned, None]
                # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù‡ÙŠ Ù†ÙØ³ Ù„ØºØ© Ø§Ù„Ù…ØµØ¯Ø±
                cleaned = summarizer.clean_summary(summary)
                return [cleaned, None]
            else:
                # Ø­ØªÙ‰ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£ØŒ Ù†Ø¸Ù Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø¬Ø¹
                cleaned = summarizer.clean_summary(text)
                return [cleaned, result["message"]]
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ: {str(e)}")
            summarizer = GroqSummarizer()
            cleaned = summarizer.clean_summary(text)
            return [cleaned, str(e)]
    
    @staticmethod
    def translate_text(text, target_lang="en", source_lang=None):
        """ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Groq API"""
        translator = SummaryTranslator.get_translator()
        return translator.translate(text, target_lang=target_lang, source_lang=source_lang)

class GroqSummarizer:
    """ÙØ¦Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·ÙˆÙŠÙ„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Groq API"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"""
        self.api_key = GROQ_API_KEY
        if not self.api_key:
            raise ValueError("ÙŠØ¬Ø¨ ØªØ¹ÙŠÙŠÙ† GROQ_API_KEY ÙÙŠ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©")
        
        self.api_url = GROQ_API_URL
        self.model = GROQ_MODEL
        self.encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ£Ø®ÙŠØ± ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
        self.initial_delay = GROQ_RATE_LIMIT_DELAY
        self.max_retries = GROQ_MAX_RETRIES
        self.max_backoff = GROQ_MAX_BACKOFF
        
        # Ø­Ø¯ÙˆØ¯ Ø§Ù„ØªÙˆÙƒÙ†Ø²
        self.max_tokens = 7000
        self.chunk_size = 6000
    
    def count_tokens(self, text: str) -> int:
        """Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆÙƒÙ†Ø² ÙÙŠ Ø§Ù„Ù†Øµ"""
        return len(self.encoding.encode(text))
    
    def detect_language(self, text: str) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ù„ØºØ© Ø§Ù„Ù†Øµ"""
        try:
            return detect(text[:1000])
        except:
            return 'en'
    
    def get_system_prompt(self, lang: str) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù„ØºØ© Ø§Ù„Ù†Øµ"""
        if lang == 'ar':
            return "Ù‚Ù… Ø¨ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ù„ØºØ© Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø®ØªØµØ±Ø©ØŒ Ø¨Ø¯ÙˆÙ† Ø¥Ø¹Ø§Ø¯Ø© ÙƒØªØ§Ø¨Ø© Ù‡Ø°Ù‡ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª ÙÙŠ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª:"
        return "Summarize the following text in clear and concise English, without including these instructions in the output:"
    
    def split_text(self, text: str) -> List[str]:
        """ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ù…Ù† Ø§Ù„ØªÙˆÙƒÙ†Ø²"""
        chunks = []
        current_chunk = []
        current_length = 0
        
        sentences = text.split('.')
        
        for sentence in sentences:
            sentence = sentence.strip() + '.'
            sentence_tokens = self.count_tokens(sentence)
            
            if sentence_tokens > self.chunk_size:
                sub_sentences = sentence.split('ØŒ' if self.detect_language(sentence) == 'ar' else ',')
                for sub_sentence in sub_sentences:
                    sub_sentence = sub_sentence.strip() + ','
                    sub_tokens = self.count_tokens(sub_sentence)
                    
                    if current_length + sub_tokens > self.chunk_size:
                        chunks.append('.'.join(current_chunk))
                        current_chunk = [sub_sentence]
                        current_length = sub_tokens
                    else:
                        current_chunk.append(sub_sentence)
                        current_length += sub_tokens
            else:
                if current_length + sentence_tokens > self.chunk_size:
                    chunks.append('.'.join(current_chunk))
                    current_chunk = [sentence]
                    current_length = sentence_tokens
                else:
                    current_chunk.append(sentence)
                    current_length += sentence_tokens
        
        if current_chunk:
            chunks.append('.'.join(current_chunk))
        
        return chunks
    
    def make_api_request(self, text: str, system_prompt: str, retry_count: int = 0) -> str:
        """Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨ Ø¥Ù„Ù‰ Groq API Ù…Ø¹ Ø¯Ø¹Ù… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text}
            ]
        }
        
        try:
            delay = min(self.initial_delay * (2 ** retry_count), self.max_backoff)
            time.sleep(delay)
            
            response = requests.post(self.api_url, headers=headers, json=data, timeout=30)
            
            if response.status_code == 429:
                if retry_count < self.max_retries:
                    print(f"âš  ØªÙ… ØªØ¬Ø§ÙˆØ² Ø­Ø¯ Ø§Ù„Ù…Ø¹Ø¯Ù„. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {retry_count + 1}/{self.max_retries}")
                    return self.make_api_request(text, system_prompt, retry_count + 1)
                raise Exception("ØªÙ… ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©")
            
            response.raise_for_status()
            result = response.json()
            
            if "choices" in result and len(result["choices"]) > 0:
                return result["choices"][0]["message"]["content"].strip()
            raise Exception("Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØºÙŠØ± ØµØ§Ù„Ø­Ø© Ù…Ù† API")
            
        except requests.exceptions.RequestException as e:
            if retry_count < self.max_retries:
                print(f"âš  Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø·Ù„Ø¨. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {retry_count + 1}/{self.max_retries}")
                return self.make_api_request(text, system_prompt, retry_count + 1)
            raise Exception(f"ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Groq API: {str(e)}")
        except Exception as e:
            if retry_count < self.max_retries:
                print(f"âš  Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {retry_count + 1}/{self.max_retries}")
                time.sleep(self.initial_delay)
                return self.make_api_request(text, system_prompt, retry_count + 1)
            raise
    
    def clean_summary(self, text: str) -> str:
        """ØªÙ†Ø¸ÙŠÙ ÙˆØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù„Ø®Øµ Ø¨Ø´ÙƒÙ„ Ø°ÙƒÙŠ: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ø±Ø¨ÙŠ ÙŠØ­Ø°Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª ØºÙŠØ± Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ ÙˆØ¥Ø°Ø§ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ ÙŠØ­Ø°Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª ØºÙŠØ± Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©."""
        if not text or not isinstance(text, str):
            return ""
        # ØªÙ†Ø¸ÙŠÙ Ø£ÙˆÙ„ÙŠ Ù„Ù„Ø±Ù…ÙˆØ² ÙˆØ§Ù„Ù…Ø³Ø§ÙØ§Øª
        text = re.sub(r'[\*\_\#\=\~\^\[\]\{\}\(\)\<\>\|\$\%\@\`\"\;]+', '', text)
        text = re.sub(r'[â€¢â—â–ªï¸âœ”ï¸â˜…â˜†â†’â†â†‘â†“â€»Â§Â¤Â°Â±Ã—Ã·]', '', text)
        text = re.sub(r'\b(THEN|SHORT SUMMARY|SUMMARY|Ù…Ù„Ø®Øµ|Ù…Ù„Ø®Øµ:|Ø®Ù„Ø§ØµØ©|Ø®Ù„Ø§ØµØ©:|Ù…Ù„Ø®ØµÙ‹Ø§|Ù…Ù„Ø®ØµØ§)\b', '', text, flags=re.IGNORECASE)
        text = re.sub(r'[A-Za-z]+:', '', text)
        text = re.sub(r'http\S+|www\S+|@[\w_]+', '', text)
        text = re.sub(r'[\u200e\u200f\u202a-\u202e]', '', text)
        text = re.sub(r'[\u061f\u060c\u061b]', '.', text)
        text = re.sub(r'[ØŸ?!ØŒØ›]+', '.', text)
        text = re.sub(r'\.{2,}', '.', text)
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'\s*\.\s*', '. ', text)
        text = re.sub(r'\n+', '\n', text)
        text = re.sub(r'\s*\n\s*', '\n', text)
        text = re.sub(r'\n{2,}', '\n', text)
        text = re.sub(r'[^\u0600-\u06FFa-zA-Z0-9\s\.\,\ØŸ\!\-\n]', '', text)
        # ØªØµØ­ÙŠØ­ Ø¨Ø¹Ø¶ Ø§Ù„ØªØ±Ø¬Ù…Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        text = text.replace('Devlet', 'Ø§Ù„Ø¯ÙˆÙ„Ø©')
        text = text.replace('Caliph', 'Ø®Ù„ÙŠÙØ©')
        text = text.replace('Omawi', 'Ø£Ù…ÙˆÙŠ')
        text = text.replace('expanded', 'ØªÙˆØ³Ø¹Øª')
        text = re.sub(r'(\b\w+\b)( \1\b)+', r'\1', text)
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù„ØºØ© Ø§Ù„ØºØ§Ù„Ø¨Ø© ÙÙŠ Ø§Ù„Ù†Øµ
        arabic_count = len(re.findall(r'[\u0600-\u06FF]', text))
        english_count = len(re.findall(r'[a-zA-Z]', text))
        lang = 'ar' if arabic_count >= english_count else 'en'
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„ ÙˆØªÙ†Ø¸ÙŠÙÙ‡Ø§
        sentences = [s.strip() for s in re.split(r'[\.\!ØŸ]', text) if s.strip()]
        cleaned_sentences = []
        for s in sentences:
            words = s.split()
            filtered_words = []
            for w in words:
                # Ø­Ø°Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ù„ØºØ© Ø§Ù„Ù†Øµ
                if lang == 'ar':
                    if re.match(r'^[\u0600-\u06FF0-9]+$', w):
                        filtered_words.append(w)
                else:
                    if re.match(r'^[a-zA-Z0-9]+$', w):
                        filtered_words.append(w)
            # Ø­Ø°Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§ (Ø­Ø±Ù Ø£Ùˆ Ø­Ø±ÙÙŠÙ†) Ø¥Ù„Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø±Ù‚Ù…
            filtered_words = [w for w in filtered_words if len(w) > 2 or w.isdigit()]
            if filtered_words:
                new_s = ' '.join(filtered_words)
                if lang == 'en' and re.match(r'^[a-zA-Z]', new_s):
                    new_s = new_s.capitalize()
                cleaned_sentences.append(new_s)
        cleaned_text = '. '.join(cleaned_sentences) + '.' if cleaned_sentences else ''
        cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
        return cleaned_text

    def summarize(self, text: str) -> Dict[str, Union[str, List[str], int]]:
        """ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†Øµ Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„ØªÙ‚Ø³ÙŠÙ… Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·ÙˆÙŠÙ„Ø©"""
        if not text.strip():
            raise ValueError("Ø§Ù„Ù†Øµ ÙØ§Ø±Øº")
        
        # Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ù„ØºØ© ÙˆØªÙˆØ­ÙŠØ¯ Ø±Ù…Ø²Ù‡Ø§
        lang = LanguageManager.normalize_language_code(TextProcessor.detect_language_safe(text))
        if not LanguageManager.is_valid_language(lang):
            print(f"âš  Ø§Ù„Ù„ØºØ© '{lang}' ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©ØŒ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©")
            lang = "en"
        
        system_prompt = self.get_system_prompt(lang)
        total_tokens = self.count_tokens(text)
        print(f"\nğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙˆÙƒÙ†Ø²: {total_tokens}")
        
        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Groq API
            if total_tokens <= self.max_tokens:
                print("ğŸ’¡ Ø§Ù„Ù†Øµ Ù‚ØµÙŠØ± Ø¨Ù…Ø§ ÙŠÙƒÙÙŠ Ù„Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±")
                summary = self.make_api_request(text, system_prompt)
                summary = self.clean_summary(summary)
                return {
                    "status": "success",
                    "original_tokens": total_tokens,
                    "chunks": [text],
                    "chunk_summaries": [summary],
                    "final_summary": summary,
                    "language": lang
                }
            
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø§Ù„Ø·ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡
            chunks = TextChunker.split_text(text, self.chunk_size)
            print(f"ğŸ“‘ ØªÙ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ {len(chunks)} Ø£Ø¬Ø²Ø§Ø¡")
            
            chunk_summaries = []
            for i, chunk in enumerate(chunks, 1):
                print(f"\nğŸ”„ Ø¬Ø§Ø±ÙŠ ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø¬Ø²Ø¡ {i}/{len(chunks)}")
                chunk_tokens = self.count_tokens(chunk)
                print(f"ğŸ“ Ø¹Ø¯Ø¯ ØªÙˆÙƒÙ†Ø² Ø§Ù„Ø¬Ø²Ø¡: {chunk_tokens}")
                
                try:
                    chunk_summary = self.make_api_request(chunk, system_prompt)
                    chunk_summary = self.clean_summary(chunk_summary)
                    chunk_summaries.append(chunk_summary)
                    print(f"âœ… ØªÙ… ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø¬Ø²Ø¡ {i}")
                except Exception as e:
                    print(f"âš  ÙØ´Ù„ ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø¬Ø²Ø¡ {i}, Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø·Ø© Ø¨Ø¯ÙŠÙ„Ø©...")
                    # Ø®Ø·Ø© Ø¨Ø¯ÙŠÙ„Ø©: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙˆÙ„ ÙˆØ¢Ø®Ø± Ø¬Ù…Ù„ØªÙŠÙ† Ù…Ù† Ø§Ù„Ø¬Ø²Ø¡
                    fallback_summary = self._create_fallback_summary(chunk)
                    chunk_summaries.append(fallback_summary)
                
                # ØªØ£Ø®ÙŠØ± Ø°ÙƒÙŠ Ø¨ÙŠÙ† Ø§Ù„Ø·Ù„Ø¨Ø§Øª
                if i < len(chunks):
                    delay = min(3 * i, 10)  # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ£Ø®ÙŠØ± ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹ Ù…Ø¹ Ø­Ø¯ Ø£Ù‚ØµÙ‰
                    print(f"â³ Ø§Ù†ØªØ¸Ø§Ø± {delay} Ø«ÙˆØ§Ù†Ù Ù‚Ø¨Ù„ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„ØªØ§Ù„ÙŠ...")
                    time.sleep(delay)
            
            print("\nğŸ”„ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ...")
            combined_summary = "\n\n".join(chunk_summaries)
            
            try:
                final_summary = self.make_api_request(combined_summary, system_prompt)
                final_summary = self.clean_summary(final_summary)
            except Exception as e:
                print("âš  ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù„Ø®ØµØ§Øª Ø§Ù„Ù…Ø¬Ø²Ø£Ø©...")
                final_summary = self._create_fallback_summary(combined_summary)
            
            print("âœ¨ Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
            
            return {
                "status": "success",
                "original_tokens": total_tokens,
                "chunks": chunks,
                "chunk_summaries": chunk_summaries,
                "final_summary": final_summary,
                "language": lang
            }
            
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {error_msg}")
            ErrorLogger.log_error("Summarization", "ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªÙ„Ø®ÙŠØµ", error_msg)
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ø¨Ø³ÙŠØ· ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„
            fallback_summary = self._create_fallback_summary(text)
            
            return {
                "status": "partial_success",
                "message": f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ø¨Ø³ÙŠØ· Ø¨Ø³Ø¨Ø¨ Ø®Ø·Ø£: {error_msg}",
                "original_tokens": total_tokens,
                "final_summary": fallback_summary,
                "language": lang
            }
    
    def _create_fallback_summary(self, text: str, max_sentences=3) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ø¨Ø³ÙŠØ· ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
        try:
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø¬Ù…Ù„
            sentences = text.split('.')
            sentences = [s.strip() for s in sentences if s.strip()]
            
            if not sentences:
                return text
            
            # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙˆÙ„ ÙˆØ¢Ø®Ø± Ø§Ù„Ø¬Ù…Ù„
            if len(sentences) <= max_sentences:
                return '. '.join(sentences) + '.'
            
            # Ø£Ø®Ø° Ø£ÙˆÙ„ Ø¬Ù…Ù„ØªÙŠÙ† ÙˆØ¢Ø®Ø± Ø¬Ù…Ù„Ø©
            selected_sentences = sentences[:2] + [sentences[-1]]
            return '. '.join(selected_sentences) + '.'
            
        except Exception as e:
            print(f"âš  ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø¨Ø³ÙŠØ·: {str(e)}")
            return text[:1000] + "..."  # Ø¥Ø±Ø¬Ø§Ø¹ Ø£ÙˆÙ„ 1000 Ø­Ø±Ù ÙƒØ­Ù„ Ø£Ø®ÙŠØ±

class LanguageManager:
    """ÙØ¦Ø© Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù„ØºØ§Øª ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­ØªÙ‡Ø§"""
    
    SUPPORTED_LANGUAGES = {
        "ar": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
        "en": "Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©",
        # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù„ØºØ§Øª Ù‡Ù†Ø§
    }
    
    @staticmethod
    def is_valid_language(lang_code):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø±Ù…Ø² Ø§Ù„Ù„ØºØ©"""
        return lang_code in LanguageManager.SUPPORTED_LANGUAGES
    
    @staticmethod
    def normalize_language_code(lang_code):
        """ØªÙˆØ­ÙŠØ¯ Ø±Ù…Ø² Ø§Ù„Ù„ØºØ©"""
        if not lang_code:
            return "en"
        lang_code = lang_code.lower().strip()
        if lang_code in ["ar", "arabic", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"]:
            return "ar"
        return "en"
    
    @staticmethod
    def get_language_name(lang_code):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³Ù… Ø§Ù„Ù„ØºØ©"""
        lang_code = LanguageManager.normalize_language_code(lang_code)
        return LanguageManager.SUPPORTED_LANGUAGES.get(lang_code, "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©")

class TranslationCache:
    """ÙØ¦Ø© Ù„Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù„ØªØ±Ø¬Ù…Ø§Øª"""
    
    _cache = {}
    _max_cache_size = 1000  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù†Ø§ØµØ± ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
    
    @staticmethod
    def _generate_cache_key(text, source_lang, target_lang):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙØªØ§Ø­ ÙØ±ÙŠØ¯ Ù„Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        text_hash = hashlib.md5(text.encode()).hexdigest()
        return f"{text_hash}:{source_lang}:{target_lang}"
    
    @staticmethod
    def get_cached_translation(text, source_lang, target_lang):
        """Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù…Ø®Ø²Ù†Ø© Ù…Ø¤Ù‚ØªØ§Ù‹"""
        cache_key = TranslationCache._generate_cache_key(text, source_lang, target_lang)
        cached_item = TranslationCache._cache.get(cache_key)
        if cached_item:
            print("âœ¨ ØªÙ… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©")
            return cached_item
        return None
    
    @staticmethod
    def cache_translation(text, source_lang, target_lang, translation):
        """ØªØ®Ø²ÙŠÙ† Ø§Ù„ØªØ±Ø¬Ù…Ø© ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©"""
        if len(TranslationCache._cache) >= TranslationCache._max_cache_size:
            # Ø­Ø°Ù Ø£Ù‚Ø¯Ù… Ø¹Ù†ØµØ± Ø¹Ù†Ø¯ Ø§Ù…ØªÙ„Ø§Ø¡ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            TranslationCache._cache.pop(next(iter(TranslationCache._cache)))
        
        cache_key = TranslationCache._generate_cache_key(text, source_lang, target_lang)
        TranslationCache._cache[cache_key] = translation
        print("âœ¨ ØªÙ… ØªØ®Ø²ÙŠÙ† Ø§Ù„ØªØ±Ø¬Ù…Ø© ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©")

class TextChunker:
    """ÙØ¦Ø© Ù„ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·ÙˆÙŠÙ„Ø©"""
    
    @staticmethod
    def split_text(text, max_chunk_size=4000, overlap=100):
        """ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ Ù…Ø¹ ØªØ¯Ø§Ø®Ù„ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø³ÙŠØ§Ù‚"""
        if len(text) <= max_chunk_size:
            return [text]
        
        chunks = []
        start = 0
        while start < len(text):
            end = start + max_chunk_size
            
            if end < len(text):
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø¬Ù…Ù„Ø© Ø£Ùˆ Ø§Ù„ÙÙ‚Ø±Ø©
                for separator in ["\n\n", "\n", ". ", ".", " "]:
                    split_pos = text.rfind(separator, start, end)
                    if split_pos != -1:
                        end = split_pos + len(separator)
                        break
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            # Ø§Ù„ØªØ­Ø±Ùƒ Ù„Ù„Ø¬Ø²Ø¡ Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© Ø§Ù„ØªØ¯Ø§Ø®Ù„
            start = max(start + max_chunk_size - overlap, end)
        
        return chunks


# ============== ØµÙØ­Ø© ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ==============
@app.route('/login', methods=['GET', 'POST'])
def login():
    error = None
    if request.method == 'POST':
        username = request.form.get('username')
        password = request.form.get('password')
        if username == USERNAME and password == PASSWORD:
            session['logged_in'] = True
            return redirect(url_for('index'))
        else:
            error = 'Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ùˆ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø©'
    return render_template('login.html', error=error)

@app.route('/logout')
def logout():
    session.pop('logged_in', None)
    return redirect(url_for('login'))

# ============== Ø­Ù…Ø§ÙŠØ© Ø§Ù„ØµÙØ­Ø§Øª ==============
def login_required(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if not session.get('logged_in'):
            return redirect(url_for('login'))
        return f(*args, **kwargs)
    return decorated_function

# Ø¹Ø¯Ù‘Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ù„ØªØªØ·Ù„Ø¨ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„
@app.route('/')
@login_required
def index():
    return render_template('index.html')

@app.route('/process', methods=['POST'])
@login_required
def process():
    try:
        print("===> Start /process endpoint")
        file = request.files.get('file')
        if not file:
            print("===> No file received")
            return jsonify({"error": "Ù„Ù… ÙŠØªÙ… ØªÙ‚Ø¯ÙŠÙ… Ù…Ù„Ù"})
        print(f"===> File received: {file.filename}")
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªØ±Ø¬Ù…Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±Ø³Ù„Ø©
        target_lang = request.form.get('target_lang', 'en')
        file_path, error = FileProcessor.process_uploaded_file(file)
        if error:
            print(f"===> Error in process_uploaded_file: {error}")
            return jsonify({"error": error})
        print(f"===> File saved to: {file_path}")
        file_ext = file_path.lower().split('.')[-1]
        if file_ext in ['wav', 'mp3', 'ogg', 'flac', 'm4a', 'webm']:
            print(f"===> Processing audio file: {file_path}")
            text = FileProcessor.process_audio_file(file_path)
        else:
            print(f"===> Unsupported file type: {file_ext}")
            return jsonify({"error": "Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…ØŒ ÙÙ‚Ø· Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ù…Ø³Ù…ÙˆØ­Ø©"})
        print(f"===> Extracted text: {text}")
        if not text:
            print("===> No text found in file")
            return jsonify({"error": "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Øµ ÙÙŠ Ø§Ù„Ù…Ù„Ù"})
        # Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ù„ØºØ© Ø§Ù„Ù†Øµ
        source_lang = TextProcessor.detect_language_safe(text)
        source_lang = LanguageManager.normalize_language_code(source_lang)
        # Ø§Ù„ØªÙ„Ø®ÙŠØµ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        summary = SummaryTranslator.process_text_for_summary(
            text,
            source_lang=source_lang,
            target_lang=target_lang
        )
        if not summary[0]:
            print("===> Failed to summarize text")
            return jsonify({"error": "ÙØ´Ù„ ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†Øµ"})
        return jsonify({
            "original_text": text if text.strip() else "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù…ØªØ§Ø­",
            "summary": summary[0],
            "source_lang": source_lang,
            "target_lang": target_lang
        })
    except Exception as e:
        ErrorLogger.log_error("Processing", "ÙØ´Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨", str(e))
        print(f"===> Exception in /process: {str(e)}")
        return jsonify({"error": f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨: {str(e)}"})

@app.route('/summarize', methods=['POST'])
@login_required
def summarize_text():
    """Ù…Ø³Ø§Ø± Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†ØµÙˆØµ ÙˆØªØ±Ø¬Ù…Ø© Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ø®ØªÙŠØ§Ø±ÙŠØ§Ù‹"""
    start_time = time.time()
    
    try:
        data = request.get_json()
        if not data or 'text' not in data:
            return jsonify({
                "status": "error",
                "message": "ÙŠØ¬Ø¨ ØªÙˆÙÙŠØ± Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªÙ„Ø®ÙŠØµÙ‡"
            })
        
        text = data['text'].strip()
        should_translate = data.get('translate', False)  # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø·Ù„Ø¨ Ø§Ù„ØªØ±Ø¬Ù…Ø©
        target_lang = data.get('target_lang', 'en')  # Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        
        if not text:
            return jsonify({
                "status": "error",
                "message": "Ø§Ù„Ù†Øµ ÙØ§Ø±Øº"
            })
        
        print("\n=== Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙ„Ø®ÙŠØµ ===")
        print(f"â± ÙˆÙ‚Øª Ø§Ù„Ø¨Ø¯Ø¡: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ” Ø§Ù„ØªØ±Ø¬Ù…Ø© Ù…Ø·Ù„ÙˆØ¨Ø©: {should_translate}")
        print(f"ğŸŒ Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©: {target_lang}")
        
        # Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ù„ØºØ© Ø§Ù„Ù†Øµ
        source_lang = TextProcessor.detect_language_safe(text)
        source_lang = LanguageManager.normalize_language_code(source_lang)
        print(f"ğŸ“ Ù„ØºØ© Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØµØ¯Ø±: {source_lang}")
        
        # Ø§Ù„ØªÙ„Ø®ÙŠØµ
        summarizer = GroqSummarizer()
        result = summarizer.summarize(text)
        
        if result["status"] == "success":
            print("\nâœ… ØªÙ… Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø¨Ù†Ø¬Ø§Ø­")
            summary = result["final_summary"]
            
            # Ø¥Ø°Ø§ ØªÙ… Ø·Ù„Ø¨ Ø§Ù„ØªØ±Ø¬Ù…Ø© ÙˆÙƒØ§Ù†Øª Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ø®ØªÙ„ÙØ© Ø¹Ù† Ù„ØºØ© Ø§Ù„Ù…ØµØ¯Ø±
            if should_translate and target_lang != source_lang:
                print(f"\nğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù…Ù„Ø®Øµ Ù…Ù† {source_lang} Ø¥Ù„Ù‰ {target_lang}...")
                translator = GroqTranslator()
                translated_summary = translator.translate(
                    summary,
                    target_lang=target_lang,
                    source_lang=source_lang
                )
                if translated_summary:
                    summary = translated_summary
                    print("âœ… ØªÙ…Øª ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù…Ù„Ø®Øµ Ø¨Ù†Ø¬Ø§Ø­")
        
            processing_time = time.time() - start_time
            print(f"\nâ± Ø²Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒÙ„ÙŠ: {processing_time:.2f} Ø«Ø§Ù†ÙŠØ©")
            
            return jsonify({
                "status": "success",
                "original_text": text,
                "summary": summary,
                "source_lang": source_lang if not should_translate else target_lang,
                "processing_time": f"{processing_time:.2f} seconds"
            })
        
        print("\nâŒ ÙØ´Ù„Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙ„Ø®ÙŠØµ")
        return jsonify({
            "status": "error",
            "message": result.get("message", "ÙØ´Ù„ ÙÙŠ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙ„Ø®ÙŠØµ"),
            "processing_time": f"{time.time() - start_time:.2f} seconds"
        })
        
    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(e)}")
        return jsonify({
            "status": "error",
            "message": f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}",
            "processing_time": f"{time.time() - start_time:.2f} seconds"
        })

# ============== ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ==============

if __name__ == '__main__':
    print("Starting app.py ...")
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…ÙØªØ§Ø­ Groq API
    if not GROQ_API_KEY:
        print("âš  ØªØ­Ø°ÙŠØ±: GROQ_API_KEY ØºÙŠØ± Ù…ØªÙˆÙØ± ÙÙŠ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©")
    else:
        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Groq API
        if not GroqAPI.test_connection():
            print("âš  ØªØ­Ø°ÙŠØ±: ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Groq API")
    
    mem = psutil.virtual_memory()
    cpu_count = os.cpu_count() or 1
    print(f"âš¡ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©: {mem.available / (1024**3):.2f} GB")
    print(f"âš¡ Ø¹Ø¯Ø¯ Ø£Ù†ÙˆÙŠØ© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬: {cpu_count}")
    
    if mem.available < 2 * 1024**3:
        print("âš  ØªØ­Ø°ÙŠØ±: Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ØªØ§Ø­Ø© Ù‚Ù„ÙŠÙ„Ø©ØŒ Ù‚Ø¯ ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡")
    
    # Clean up files older than 24 hours
    ResourceManager.cleanup_temp_files(older_than_hours=24)
    
    port = int(os.environ.get("PORT", 3000))  # Use 3000 for Replit compatibility
    app.run(
        debug=False,
        threaded=True,
        processes=1,
        host='0.0.0.0',
        port=port,
    )

